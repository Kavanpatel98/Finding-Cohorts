{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67d78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd \n",
    "import datefinder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pytz\n",
    "import spacy\n",
    "import multiprocessing\n",
    "from nltk import tokenize\n",
    "import concurrent.futures\n",
    "import winprocess\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45f97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document from which date need to be extracted\n",
    "doc = \"Given medical Report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658c3060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.371695041656494\n"
     ]
    }
   ],
   "source": [
    "# load pre-require library\n",
    "start = time.time()\n",
    "med7 = spacy.load(\"en_core_med7_lg\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5649c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract unique dates\n",
    "def extract_unique_dates(doc):    \n",
    "    extracted_dates = []\n",
    "    dates = search_dates(doc)\n",
    "    list_of_extracted_dates = []\n",
    "    for text_date in dates:\n",
    "        list_of_extracted_dates.append(text_date[0])\n",
    "    unique_dates = [x for i, x in enumerate(list_of_extracted_dates) if i == list_of_extracted_dates.index(x)]\n",
    "    return(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0290f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fine start index\n",
    "def find_starting_index(list_entity,doc):\n",
    "    start_index = []\n",
    "    for entity in list_entity:\n",
    "        start_index.append([m.start() for m in re.finditer(entity, doc)])\n",
    "    return start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37190bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find end index \n",
    "def find_ending_index(list_entity,doc):\n",
    "    end_index = []\n",
    "    for entity in list_entity:\n",
    "        end_index.append([m.end() for m in re.finditer(entity, doc)])\n",
    "    return end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b53ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get length of array\n",
    "def arr_dimen(a):\n",
    "    return [len(a)]+arr_dimen(a[0]) if(type(a) == list) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be078872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find unique values from list and return in array\n",
    "def unique(list1):\n",
    "    x = np.array(list1)\n",
    "    return (np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e31915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find unique values from list and return in list\n",
    "def unique_list(list1):\n",
    " \n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e25725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get mean of starting and ending index\n",
    "def get_mean_distance(starting_index_list, ending_index_list):\n",
    "    if len(arr_dimen(starting_index_list)) > 1:\n",
    "        mean_index = []\n",
    "        for i in range(len(starting_index_list)):\n",
    "            mean_index.append([(g + h) / 2 for g, h in zip(starting_index_list[i], ending_index_list[i])])\n",
    "    else:\n",
    "        mean_index = [(g + h) / 2 for g, h in zip(starting_index_list, ending_index_list)]\n",
    "    return mean_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b514b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate distance between entity and date\n",
    "def calculate_distance(index_date_list,index_entity_list,unique_list_dates):\n",
    "    date = []\n",
    "    distance = []\n",
    "    for index_val in tqdm(range(len(index_date_list))):\n",
    "        if len(index_date_list[index_val]) > 1:\n",
    "            for sub_index_value in range(len(index_date_list[index_val])):\n",
    "                date.append(unique_list_dates[index_val])\n",
    "                distance.append(abs(index_date_list[index_val][sub_index_value]-index_entity_list[0]))\n",
    "        elif len(index_date_list[index_val]) == 1:\n",
    "            date.append(unique_list_dates[index_val])\n",
    "            distance.append((abs(index_date_list[index_val][0]-index_entity_list[0])))\n",
    "        else:\n",
    "            pass\n",
    "    d = {'Date':date,'Distance':distance}\n",
    "    cal_distance = pd.DataFrame(d)\n",
    "    return cal_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf3e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to closed date based on distance\n",
    "def find_date_based_distance(df_with_date_distance):\n",
    "    cal_distance = df_with_date_distance.sort_values(by='Distance')\n",
    "    return cal_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93808c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform basic data cleaning on medical report\n",
    "def basic_clean(doc):\n",
    "    new_doc = \" \".join(doc.split())\n",
    "    str_1 = re.sub(r\"[\\[\\*\\]\\{\\}\\(\\)]\", \" \", new_doc)\n",
    "    return \" \".join(str_1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f26f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract date manually from medical report\n",
    "def extract_Date_manual(doc):\n",
    "    my_txt=doc\n",
    "    matches  = datefinder.find_dates(my_txt, source=True)\n",
    "    detect_dates=[]\n",
    "    for match in matches:\n",
    "        try:\n",
    "            detect_dates.append(match)\n",
    "        except calendar.IllegalMonthError:\n",
    "            print(\"Caught it!\")\n",
    "\n",
    "    list_of_extracted_dates = []\n",
    "    for text_date in detect_dates:\n",
    "            list_of_extracted_dates.append(text_date[1])\n",
    "    \n",
    "    unique_dates = [x for i, x in enumerate(list_of_extracted_dates) if i == list_of_extracted_dates.index(x)]\n",
    "    selected_Date=[]\n",
    "    for i in unique_dates:\n",
    "        if \".\" in i or i.isdigit() == True or \"of\" in i or \"at\" in i:\n",
    "            pass\n",
    "        else:\n",
    "            selected_Date.append(i)\n",
    "    return(selected_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60236099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify medical terms\n",
    "def med_terms(doc):\n",
    "    doc1 = med7(doc)\n",
    "    med_rec = pd.DataFrame([(ent.text, ent.label_) for ent in doc1.ents], columns =['Entity', 'Tag']) \n",
    "    Date_ext_med = med_rec[med_rec['Tag'].isin(['DOSAGE', 'DURATION','FORM','FREQUENCY','ROUTE','STRENGTH'])]\n",
    "    return Date_ext_med\n",
    " \n",
    "# function to identify date using spacy     \n",
    "def date_spacy(doc):\n",
    "    text2= nlp(doc)\n",
    "    Date_ext = pd.DataFrame([(ent.text, ent.label_) for ent in text2.ents], columns =['Entity', 'Tag']) \n",
    "    Date_ext = Date_ext[Date_ext['Tag'].isin(['TIME', 'DATE'])]\n",
    "    return Date_ext\n",
    "\n",
    "# function to generate check list based on medical terms\n",
    "def generate_check_string(Date_ext_med):\n",
    "    check_string = ' '.join(word for word in Date_ext_med.Entity.tolist())\n",
    "    return(check_string)\n",
    "\n",
    "# function to get extracted date from spacy\n",
    "def final_spacy_dates(Date_ext,check_string):\n",
    "    selected_date = [entity for entity in Date_ext.Entity.tolist() if str(entity) not in check_string]\n",
    "    return(selected_date)\n",
    "\n",
    "# function to return manual extracted dates\n",
    "def final_manual_extracted_date(extract_date,check_string):\n",
    "    selected_date_1 = [entity for entity in extract_date if str(entity) not in check_string]\n",
    "    return selected_date_1\n",
    "\n",
    "# function to perform similarity check between two dates\n",
    "def similarity_check_dates(selected_date_1,selected_date):\n",
    "    Final_selected_date = []\n",
    "    selected_date_1 = [nlp(str(entity)) for entity in selected_date_1]\n",
    "    selected_date_nlp = [nlp(str(entity)) for entity in selected_date]\n",
    "    for entity in selected_date_1:\n",
    "        dummy = []\n",
    "        for med_ent in selected_date_nlp:\n",
    "            dummy.append(entity.similarity(med_ent))\n",
    "        if any(y > 0.90 for y in dummy):\n",
    "            pass\n",
    "        else:\n",
    "            Final_selected_date.append(entity)\n",
    "    Date_selected = selected_date + Final_selected_date\n",
    "    return(Date_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c0b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Date function which will extract all date from medical report\n",
    "def find_date(doc):\n",
    "    doc = basic_clean(doc)\n",
    "    start = time.time()\n",
    "    med_term = med_terms(doc)\n",
    "    spacy_date = date_spacy(doc)\n",
    "    check_string = generate_check_string(med_term)\n",
    "    selected_spacy_dates = final_spacy_dates(spacy_date,check_string)\n",
    "    extracted_date = extract_Date_manual(doc)\n",
    "    selected_manual_date = final_manual_extracted_date(extracted_date,check_string)\n",
    "    list_of_dates = similarity_check_dates(selected_manual_date,selected_spacy_dates)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    return list_of_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dd72122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-07-10 07/10/2020',\n",
       " 'today',\n",
       " '71-year-old',\n",
       " '3 years',\n",
       " 'the past month',\n",
       " '08/31/2020',\n",
       " '07/11/2020',\n",
       " '21:50:44',\n",
       " '2020-09-01',\n",
       " '2 weeks',\n",
       " '2 days',\n",
       " 'today',\n",
       " '75mg daily 4',\n",
       " 'April 2020',\n",
       " '30 years',\n",
       " '60s',\n",
       " '2020-09-04',\n",
       " '09/04/2020 11:53',\n",
       " '72 year old',\n",
       " 'Two weeks ago',\n",
       " '08/30/2020',\n",
       " '08/31/2020',\n",
       " '5 PM',\n",
       " 'Pregabalin lyrica 150 MG PO bedtime',\n",
       " '08/30/2020',\n",
       " '24 Hours',\n",
       " 'age 74-Mother',\n",
       " 'age 84',\n",
       " '2020/09/03',\n",
       " '2020/09/03',\n",
       " '18 mg',\n",
       " '2020/09/03',\n",
       " '2020/09/03',\n",
       " '2020/09/03',\n",
       " '2020/09/03',\n",
       " '15:06 - PT',\n",
       " 'today',\n",
       " 'today',\n",
       " 'today',\n",
       " '09/04/2020 11:53 Record',\n",
       " '2020-09-08',\n",
       " '72 year old',\n",
       " '1st',\n",
       " 'today',\n",
       " 'April 2020',\n",
       " '30 years',\n",
       " '72 year old',\n",
       " 'today',\n",
       " 07/20/2021,\n",
       " on 08/31/2020,\n",
       " 07/11/2020 21:50:44,\n",
       " 8/30/35,\n",
       " 1-4,\n",
       " on 9/01/35,\n",
       " 4, 1/6,\n",
       " On 08/30/2020,\n",
       " On 08/31/2020,\n",
       " 09/01/2020,\n",
       " 2, 2/6,\n",
       " on -- -- 2020/09/04 09:13,\n",
       " 2020/09/04 09:13,\n",
       " 2020/09/03 15:06,\n",
       " 2020/09/04 07:42,\n",
       " 2020/09/03 15:09,\n",
       " on 09/01,\n",
       " 09/04,\n",
       " on 09/04/2020 11:53,\n",
       " on 8/30/35,\n",
       " on 9/02/35,\n",
       " 9/03/35,\n",
       " 9/04/35,\n",
       " 9/05/35,\n",
       " wed by,\n",
       " on 9/06/35,\n",
       " 1/6,\n",
       " 9/08/35,\n",
       " on 9/05/35,\n",
       " on 20]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1 = find_date(doc)\n",
    "R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef8915eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that call document tagger API of Orion Health\n",
    "def _call_pipeline_n_grams_tagging(text):\n",
    "    url = \"http://172.20.28.32:6010/pipeline/n_gram_tagging\"\n",
    "    body = json.dumps({\"text\": text})\n",
    "    param = {\"combine_sentences\": \"True\", \"threshold\": \"0.90\", \"grams_num\": \"3\", \"concepts_num\": \"3\",\n",
    "             \"use_gpu_encoder\": \"True\"}\n",
    "    headers = {'content-type': 'application/json', 'accept': 'application/json'}\n",
    "    response = requests.post(url, params=param, data=body, headers=headers, allow_redirects=False)\n",
    "    output = json.loads(response.text)\n",
    "    return output\n",
    "tagging_out = _call_pipeline_n_grams_tagging(basic_clean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f322b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that find all disorder entity from given medical report\n",
    "def find_disorder_entity(tagging_out,concept_type_string):   \n",
    "    entity = []\n",
    "    entity_starting_index = []\n",
    "    entity_ending_index = []\n",
    "    for single_entity_info in tagging_out['entities']:\n",
    "        idef _call_pipeline_n_grams_tagging(text):\n",
    "    url = \"http://172.20.28.32:6010/pipeline/n_gram_tagging\"\n",
    "    body = json.dumps({\"text\": text})\n",
    "    param = {\"combine_sentences\": \"True\", \"threshold\": \"0.90\", \"grams_num\": \"3\", \"concepts_num\": \"3\",\n",
    "             \"use_gpu_encoder\": \"True\"}\n",
    "    headers = {'content-type': 'application/json', 'accept': 'application/json'}\n",
    "    response = requests.post(url, params=param, data=body, headers=headers, allow_redirects=False)\n",
    "    output = json.loads(response.text)\n",
    "    return outputf single_entity_info['possible_concepts'][0]['concept_type'] == concept_type_string:\n",
    "            entity.append(single_entity_info['entity_content'])\n",
    "            entity_starting_index.append(single_entity_info['start_index'])\n",
    "            entity_ending_index.append(single_entity_info['end_index'])\n",
    "    return entity,entity_starting_index,entity_ending_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4aa761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extract closest date for all entity\n",
    "def find_list_date_by_distance(entity_list, start_index_list, ending_index_list, doc,list_of_dates):\n",
    "    doc = basic_clean(doc)\n",
    "    \n",
    "    start_index_date = find_starting_index(list_of_dates,doc)\n",
    "    end_index_date = find_ending_index(list_of_dates,doc)\n",
    "    \n",
    "    entity_name = []\n",
    "    str_inx = []\n",
    "    end_ind = []\n",
    "    selected_date = []\n",
    "    f_distance = []\n",
    "    \n",
    "    for entity in range(len(entity_list)):\n",
    "        start_index_entity = [start_index_list[entity]]\n",
    "        end_index_entity = [ending_index_list[entity]]\n",
    "    \n",
    "        mean_index_date = get_mean_distance(start_index_date,end_index_date)\n",
    "        mean_index_entity = get_mean_distance(start_index_entity,end_index_entity)\n",
    "    \n",
    "        cal_dist = calculate_distance(mean_index_date,mean_index_entity,list_of_dates)\n",
    "        dates_according_distance = find_date_based_distance(cal_dist)\n",
    "    \n",
    "        entity_name.append(entity_list[entity])\n",
    "        str_inx.append(start_index_entity)\n",
    "        end_ind.append(end_index_entity)\n",
    "        selected_date.append(dates_according_distance.Date.head(1).tolist()[0])\n",
    "        f_distance.append(dates_according_distance.Distance.head(1).tolist()[0])\n",
    "    d = {'Entity':entity_name,'Start_index':str_inx,'End_index':end_ind,'Date':selected_date,'Distance':f_distance}\n",
    "    c_d = pd.DataFrame(d)\n",
    "    return c_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48b4f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_out = _call_pipeline_n_grams_tagging(basic_clean(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecf0c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disorder_entity,disorder_entity_starting_index,disorder_entity_ending_index = find_disorder_entity(tagging_out,'disorder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e59585dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 196055.59it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 401022.80it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 146368.73it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 155533.46it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 154780.73it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 221901.60it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 250100.24it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 369729.11it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 156102.83it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 379040.81it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 139657.50it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 140270.04it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 219239.54it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 156389.09it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 200041.08it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 123540.58it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 146620.37it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 390614.57it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 183144.27it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 367604.23it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 205504.05it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 172407.37it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 150856.45it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 137777.35it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 207504.09it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 217746.85it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 383587.02it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 427132.79it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 201300.19it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 145288.21it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 142854.58it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 111482.59it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 175722.90it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 394225.80it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 396056.57it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 174286.47it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 130337.52it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 403552.91it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 336648.08it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 367604.23it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 171828.44it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 438855.14it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 354366.40it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 164429.66it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 121027.69it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 314315.16it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 319416.41it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 134376.34it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 365503.63it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 432914.63it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 321422.79it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 128118.45it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 388833.65it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 325926.81it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 316649.19it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 279926.20it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 161829.57it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 265132.17it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 168545.81it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 371338.96it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 381300.36it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 322232.42it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 146201.45it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 180304.82it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 217192.31it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 140578.32it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 138373.47it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 302069.12it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 445736.14it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 476447.94it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 409364.07it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 472925.22it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 461827.70it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 465186.44it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 137112.83it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 279620.27it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 349048.49it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 476447.94it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 242284.61it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 217746.85it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 333575.68it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 473801.01it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 507643.94it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 444960.95it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 369729.11it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 206166.43it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 128440.03it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 293072.79it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 401022.80it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 476447.94it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 406760.80it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 483653.20it/s]\n"
     ]
    }
   ],
   "source": [
    "result = find_list_date_by_distance(disorder_entity,disorder_entity_starting_index,disorder_entity_ending_index,doc,unique_list(list_of_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0411ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Start_index</th>\n",
       "      <th>End_index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trigeminal neuralgia</td>\n",
       "      <td>[370]</td>\n",
       "      <td>[390]</td>\n",
       "      <td>71-year-old</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hypothyroidism</td>\n",
       "      <td>[793]</td>\n",
       "      <td>[807]</td>\n",
       "      <td>the past month</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asthma</td>\n",
       "      <td>[826]</td>\n",
       "      <td>[832]</td>\n",
       "      <td>the past month</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trigeminal neuralgia</td>\n",
       "      <td>[1344]</td>\n",
       "      <td>[1364]</td>\n",
       "      <td>on 08/31/2020</td>\n",
       "      <td>433.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuts</td>\n",
       "      <td>[1872]</td>\n",
       "      <td>[1876]</td>\n",
       "      <td>08/31/2020</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TD</td>\n",
       "      <td>[2076]</td>\n",
       "      <td>[2078]</td>\n",
       "      <td>07/11/2020</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TR</td>\n",
       "      <td>[2100]</td>\n",
       "      <td>[2102]</td>\n",
       "      <td>21:50:44</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHF</td>\n",
       "      <td>[2321]</td>\n",
       "      <td>[2324]</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LE</td>\n",
       "      <td>[2608]</td>\n",
       "      <td>[2610]</td>\n",
       "      <td>8/30/35</td>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trigeminal neuralgia</td>\n",
       "      <td>[3116]</td>\n",
       "      <td>[3136]</td>\n",
       "      <td>today</td>\n",
       "      <td>133.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Entity Start_index End_index            Date  Distance\n",
       "0  trigeminal neuralgia       [370]     [390]     71-year-old      56.5\n",
       "1        Hypothyroidism       [793]     [807]  the past month     197.0\n",
       "2                asthma       [826]     [832]  the past month     226.0\n",
       "3  trigeminal neuralgia      [1344]    [1364]   on 08/31/2020     433.5\n",
       "4                  cuts      [1872]    [1876]      08/31/2020      85.0\n",
       "5                    TD      [2076]    [2078]      07/11/2020       8.0\n",
       "6                    TR      [2100]    [2102]        21:50:44       6.0\n",
       "7                   CHF      [2321]    [2324]         2 weeks      97.0\n",
       "8                    LE      [2608]    [2610]         8/30/35      61.5\n",
       "9  Trigeminal neuralgia      [3116]    [3136]           today     133.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date associate with medical terms \n",
    "result.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
